{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f80c066-0e14-4547-87b4-d9856f43a9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import os,re,math,pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict,Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0df9877a-1e0a-4ec9-b92b-02c1730186c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading dataset\n",
    "DATA=\"../data/data.csv\"\n",
    "TEST=\"../data/test.csv\"\n",
    "OUT_MODEL=\"../models/trigram_model_full.pkl\"\n",
    "os.makedirs(os.path.dirname(OUT_MODEL),exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab3286e7-ab80-4469-9019-3aeba05c8d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "df=pd.read_csv(DATA)\n",
    "corpus=df['text'].dropna().astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1f3dd53-672e-46a4-8514-0bcbdd0ffc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', \"i'm\", '20']\n"
     ]
    }
   ],
   "source": [
    "#preprocess helper\n",
    "tok_re=re.compile(r\"[a-z0-9']+\")\n",
    "def preprocess(s):\n",
    "    return tok_re.findall(s.lower())\n",
    "\n",
    "print(preprocess(\"Hello, I'm 20.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b7b3659-6304-476b-8052-e78ab4eba81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab: 64804 train_sents: 40000\n"
     ]
    }
   ],
   "source": [
    "#building tokens and vocab with <unk> (min_count)\n",
    "tokens=[ ['<s>']+preprocess(s)+['</s>'] for s in corpus ]\n",
    "ctr=Counter(w for sent in tokens for w in sent)\n",
    "min_count=2   # change to 1 if very small train set\n",
    "vocab=[w for w,c in ctr.items() if c>=min_count]\n",
    "for t in ['<s>','</s>','<unk>']:\n",
    "    if t not in vocab: vocab.append(t)\n",
    "vocab=sorted(set(vocab))\n",
    "v2i={w:i for i,w in enumerate(vocab)}\n",
    "i2v={i:w for w,i in v2i.items()}\n",
    "V=len(vocab)\n",
    "train_mapped=[[ w if w in v2i else '<unk>' for w in sent ] for sent in tokens]\n",
    "print('vocab:',V,'train_sents:',len(train_mapped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c7e44cb-fc04-4660-877c-6f1b1dec2e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique bigrams: 1943148 tot_unigrams: 9409877\n"
     ]
    }
   ],
   "source": [
    "#building sparse counts efficiently\n",
    "bigram_next=defaultdict(Counter)\n",
    "bigram=Counter()    \n",
    "bigram2=defaultdict(Counter)\n",
    "unigrams=Counter()\n",
    "tot_unigrams=0\n",
    "\n",
    "for s in train_mapped:\n",
    "    L=len(s)\n",
    "    for i in range(L-2):\n",
    "        w1,w2,w3=s[i],s[i+1],s[i+2]\n",
    "        bigram_next[(w1,w2)][w3]+=1\n",
    "        bigram[(w1,w2)]+=1\n",
    "        bigram2[w2][w3]+=1\n",
    "        unigrams[w3]+=1\n",
    "        tot_unigrams+=1\n",
    "print('unique bigrams:',len(bigram_next),'tot_unigrams:',tot_unigrams)\n",
    "#precomputing denominators\n",
    "bigram_denom={bn:count for bn,count in bigram.items()}\n",
    "bigram2_denom={w2:sum(cnt.values()) for w2,cnt in bigram2.items()}\n",
    "unigram_denom=tot_unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd055059-0c74-44dc-b111-aab58009dfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparams\n",
    "alpha=1.0\n",
    "lam3,lam2,lam1=0.6,0.3,0.1\n",
    "def prob_trigram(w1,w2,w3):\n",
    "    bn=(w1,w2)\n",
    "    if bn in bigram_next:\n",
    "        num=bigram_next[bn].get(w3,0)+alpha\n",
    "        den=bigram_denom.get(bn,0)+alpha*V\n",
    "        return num/den\n",
    "    return 0.0\n",
    "\n",
    "def prob_bigram(w2,w3):\n",
    "    num=bigram2[w2].get(w3,0)+alpha\n",
    "    den=bigram2_denom.get(w2,0)+alpha*V\n",
    "    return num/den if den>0 else 0.0\n",
    "\n",
    "def prob_unigram(w3):\n",
    "    return (unigrams.get(w3,0)+alpha) / (unigram_denom+alpha*V) if unigram_denom>0 else 1.0/V\n",
    "\n",
    "def prob_combined(w1,w2,w3):\n",
    "    p3=prob_trigram(w1,w2,w3)\n",
    "    p2=prob_bigram(w2,w3)\n",
    "    p1=prob_unigram(w3)\n",
    "    return lam3*p3 + lam2*p2 + lam1*p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a0096df-07c4-4e89-9d4a-5ff01e3e027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#greedy prediction and generation \n",
    "def predict_next(w1,w2):\n",
    "    bn=(w1,w2)\n",
    "    if bn in bigram_next and bigram_next[bn]:\n",
    "        return max(bigram_next[bn].items(), key=lambda x:x[1])[0]\n",
    "    if bigram2[w2]:\n",
    "        return max(bigram2[w2].items(), key=lambda x:x[1])[0]\n",
    "    return max(unigrams.items(), key=lambda x:x[1])[0] if unigrams else '</s>'\n",
    "\n",
    "def generate(start=('the','quick'),maxlen=20):\n",
    "    w1,w2=start\n",
    "    out=[w1,w2]\n",
    "    for _ in range(maxlen):\n",
    "        nxt=predict_next(w1,w2)\n",
    "        out.append(nxt)\n",
    "        if nxt=='</s>': break\n",
    "        w1,w2=w2,nxt\n",
    "    return ' '.join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7093d5a2-85dd-44f5-ab4c-95eb8310a73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample prob: 1.844581262577135e-05\n",
      "predict: and\n",
      "gen: the quick and the film is a very good and the film is a very good and the film is a very\n",
      "saved model -> ../models/trigram_model_full.pkl\n"
     ]
    }
   ],
   "source": [
    "#testing and save model\n",
    "print('sample prob:',prob_combined('the','quick','brown'))\n",
    "print('predict:',predict_next('the','quick'))\n",
    "print('gen:',generate(('the','quick')))\n",
    "\n",
    "to_save={\n",
    "    'vocab':vocab,'v2i':v2i,'i2v':i2v,\n",
    "    'bigram_next':bigram_next,'bigram':bigram,'bigram_denom':bigram_denom,\n",
    "    'bigram2':bigram2,'bigram2_denom':bigram2_denom,\n",
    "    'unigrams':unigrams,'unigram_denom':unigram_denom,\n",
    "    'tot_unigrams':tot_unigrams,\n",
    "    'alpha':alpha,'lam':(lam3,lam2,lam1)\n",
    "}\n",
    "with open(OUT_MODEL,'wb') as f:\n",
    "    pickle.dump(to_save,f,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('saved model ->',OUT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b696f6d-f9c8-4cef-8000-fb6ae1bd17c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 64804\n",
      "observed bigrams: 1943148\n",
      "sample prob: 1.5422816514751925e-05\n",
      "predict: and\n",
      "gen: the quick and the film is a very good and the film is a very good and the film is a very\n"
     ]
    }
   ],
   "source": [
    "#tests\n",
    "print('vocab size:',V)\n",
    "print('observed bigrams:',len(bigram_next))\n",
    "print('sample prob:',trigram_prob('the','quick','brown'))\n",
    "print('predict:',predict_next('the','quick'))\n",
    "print('gen:',generate(('the','quick')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbfa0df2-646b-453d-9b39-b71da4366966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test tokens: 1178808 known tokens: 1168208 coverage: 0.9910078655726802\n",
      "test trigrams: 1178808 perplexity: 1764.2275509946078\n"
     ]
    }
   ],
   "source": [
    "#evaluation test on test.csv\n",
    "df_test=pd.read_csv(TEST)\n",
    "test_sents=df_test['text'].dropna().astype(str).tolist()\n",
    "\n",
    "unk_present = '<unk>' in v2i\n",
    "def map_tokens(s):\n",
    "    toks=preprocess(s)\n",
    "    if unk_present:\n",
    "        return ['<s>'] + [ (w if w in v2i else '<unk>') for w in toks ] + ['</s>']\n",
    "    return ['<s>'] + toks + ['</s>']\n",
    "\n",
    "test_tokens=[ map_tokens(s) for s in test_sents ]\n",
    "\n",
    "#coverage\n",
    "flat=[w for sent in test_tokens for w in sent if w not in ('<s>','</s>')]\n",
    "known=sum(1 for w in flat if w in v2i and w!='<unk>')\n",
    "coverage = known/len(flat) if flat else 0.0\n",
    "print('test tokens:',len(flat),'known tokens:',known,'coverage:',coverage)\n",
    "\n",
    "#computing perplexity\n",
    "sum_log=0.0; N=0\n",
    "for sent in test_tokens:\n",
    "    for i in range(len(sent)-2):\n",
    "        w1,w2,w3=sent[i],sent[i+1],sent[i+2]\n",
    "        p=prob_combined(w1,w2,w3)\n",
    "        if p<=0: p=1e-12\n",
    "        sum_log += math.log(p); N+=1\n",
    "\n",
    "ppl=math.exp(-sum_log/N) if N>0 else float('inf')\n",
    "print('test trigrams:',N,'perplexity:',ppl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
